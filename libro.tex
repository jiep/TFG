\section{Rank Aggregation -- Part 1 \cite{langville2012s}}

El objetivo de la agregación de rankings es mezclar varios rankings para construir uno nuevo ranking. La necesidad rankings agregados tiene muchas aplicaciones como, por ejemplo, los meta buscadores como Excite, Hotbot, Clusty que combinan los rankings de distintos buscadores en uno solo.\\

El proceso anterior se llama agregación de rankings.\\

\begin{teo}[de Imposibilidad de Arrow]
No existe un sistema de votación que cumpla las siguientes cuatro propiedades simultáneamente:

\begin{itemize}
\item Dominio no restringido
\item Independencia de alternativas irrelevantes
\item Principio de Pareto
\item Sin dictadores
\end{itemize}
\end{teo}

Métodos de agregación de rankings:
\begin{itemize}
\item Método de Borda
\item Ranking promedio
\item Datos de juego simulado (Simulated Game Data)
\item Teoría de grafos para la agregación de rankings
\end{itemize}

\subsection{Método de Borda}

Este método fue creado por Jean-Charles de Borna y data de 1770. Borda intentaba agregar rankings de listas de candidatos de unas elecciones políticas. Para cada lista de candidatos, cada candidato recibía a puntuación igual al número de candidatos que le superan. La puntuación de cada lista es sumada para cada candidato para crear un solo ranking, que se llama la ``cuenta de Borda\footnote{Traducción de Borda Count}''. Los candidatos son ordenados en orden descendiente según este método. Este método puede ser adaptado para  manejar empates. Notar que los empates rompen las puntuaciones de Borda de las posiciones fijadas del ranking. Este método puede manejar rankings de entrada con empates. Además, también puede producir un ranking de salida que contenga empates. Aunque este método es muy sencillo, tiene un gran problema: que es fácil manipulable. Ejemplos que demuestran esta fragilidad se pueden ver en la Ref. 16 de~\cite{langville2012s}.

\subsection{Ranking promedio}  

Otro método muy sencillo de agregación de rankings es el ranking promedio. En este caso, los enteros que representan el orden en el ranking en los múltiples rankings se hace la media con éstos para crear la lista agregada. Una desventaja de este método es la frecuente aparición de empates en el rating. \\

Hay varias estrategias para romper los empates. Expondremos dos. La primera estrategia hace uso de los datos pasados para romper los empates. La segunda, es asignar una lista ordenada como ``lista tie-break``, que funciona bien para parejas de empates.\\

Notar que este método sólo puede usarse cuando todos los rankings contienen todos los mismos elementos. Otra observación es que este método puede producir una agregación de rankings que no contenga un ranking. 

\subsection{Simulated Game Data}

Este método tiene como regla una interpretación una interpretación simple de un ranking: ``si el equipo A aparece por encima del equipo B en un ranking, entonces en un partido entre los dos equipos, A debería ganar a B''. Además, si el equipo A aparece en la cima del ranking y juega contra el equipo B, que aparece al final del ranking, entonces esperaríamos que el equipo A ganara al equipo B por un gran margen.\\

Para asignar este margen entre distintos equipos, podemos asignar como margen de victoria un punto por cada diferencia de posiciones en el ranking. Estas puntuaciones son útiles cuando en la agregación del ranking. Podemos observar que los rankings no necesitan ser completos, como la mayoría de los métodos de agregación.\\

Algunas de las propiedades de los datos simulados son:

\begin{itemize}
\item El ranking agregado es tan bueno (o malo) como lo sean los rankings de entrada.
\item El método de combinación actúa como ``alisante'' que minimiza el efecto de los outliers, que son rankings que contienen  anomalías que hace que sean inconsistentes con los rankings en otros rankings. 
\item El ranking agregado cumple el principio de Pareto si los rankings de entrada lo cumplen.
\item El método de combinación puede tener efectos en el ranking agregado. Además, si el método de combinación es uno de los métodos de entrada, entonces el método puede ser llamado un dictador parcial, en el lenguaje de Arrow.    
\end{itemize}

\subsection{Teoría de grafos para la agregación de rankings}
 
 Este método utiliza la teoría de grafos. Cada uno del grafo es un equipo y cada arco puede ser información que venga de los rankings que queremos agregar. Por ejemplo, podemos considerar, un peso $w_{ij}$ desde $i$ a $j$ como sigue:
 
 \[ w_{ij} = \text{ número de rankings que tienen a } i \text{ por debajo de } j \]
 o 
 \[ w_{ij} = \text{ suma de diferencia de rankings que tienen a } i \text{ por debajo de } j \]
 
 Cualquier algoritmo famoso como el PageRank, HITS, SALSA, etc. puede servir para dar peso a los arcos del grafo.
 
 \subsection{Un refinamiento después de la agregación de rankings}
 
 Cuando varios rankings se han agregado en uno solo usando algún método de la sección anterior, un refinamiento llamado Kemenización y puede ser implementado para mejorar el ranking agregado. Un ranking agregado se dice localmente Kemeny óptimo si no existe un intercambio de posiciones de un ranking de entrada y el ranking agregado que reduzca la suma de la tau de Kendall entre cada ranking de entrada y el ranking agregado. La kemenización local considera cada par del ranking agregado y pregunta lo siguiente: ¿un intercambio de posiciones la tau de Kendall? Para un ranking agregado con $n$ elementos, la kemenización local requiere $n-1$ comprobaciones, una por cada par de vecinos.
 
 \subsection{Agregación de ratings}
 
 Los ratings también pueden agregarse como los rankings, pero tenemos que solventar varios problemas: uno de ellos son las escalas de los diferentes ratings. Por ejemplo, el método de Colley produce ratings rondando 0.5, mientras que las cadenas de Markov produce ratings entre 0 y 1. Para poner todos los ratings en la misma escala usaremos las distancias y los porcentajes. Un rating de $n$ elementos contiene $\binom{n}{2} = n(n-1)/2$ de parejas que comparar entre los $n$ elementos. Podemos tomar las diferencias positivas para crear una matriz simétrica no negativa de diferencias para cada rating. Para poner todas las distancias en la misma escala normalizamos la matriz como sigue: cada elemento de la matriz, la dividimos por la suma de todas las distancias en la matriz. Un método sencillo de agregación de ratings consiste en hacer la media ponderada de cada matriz.
 
 \subsubsection{Rankings a partir de las matrices de rating agregadas}
 
 \paragraph{Método 1} El primer método usa la suma de las columnas y las filas. La suma de las filas da una medida de cómo es el equipo de ofensivo, mientras que la suma de las columnas da una medida de cómo de defensivo es un equipo. Si el rating ofensivo es $o = \bar{R}e$ y el vector defensivo es $d e^{T} \bar{R}$, donde $\bar{R}$ es la matriz de los rating y $e$ es un vector de unos. El rating total se puede calcular como $r=o/d$. 
 
 \paragraph{Método 2} El segundo método usa el método de las cadenas de Markov aplicado a una versión normalizada de las filas $\bar{R}^{T}$. Esto funciona porque las las entrada de $\bar{R}$ son las distancias entre los equipos.
 
 \paragraph{Método 3} El tercer método usa el autovector dominante de $\bar{R}$. Este vector se denomina vector de Perron de $\bar{R}$. Este vector recibe su nombre del teorema de Perron de una matriz irreducible no negativa que asegura que es no negativo. En vez de comprobar que $\bar{R}$ es irreducible, en la práctica uno puede forzar la irreducibilidad añadiendo $\epsilon e e^T$ a $\bar{R}$, donde $\epsilon$ es un número pequeño y positivo.
 
 \section{Rank Aggregation -- Part 2} 
 
 Los métodos de agregación de rankings estudiados hasta ahora, son métodos heurísticos, es decir, que no tenemos garantías de que sean óptimos. Por otra parte, estos métodos son muy rápidos.\\
 
 A continuación describimos un método de agregación de rankings, que fue creado por el Dr. Yoshitsugu Yamamoto de la Universidad de Tsukuba en Japón. Este método produce un ranking agregado que optimiza la conformidad entre los rankings de entrada. Hay varias maneras de definir la conformidad entre los rankings, por ejemplo, podemos considerar la siguiente:
 
 \[ c_{i,j} = (\text{ número de rankings con } i \text{ por encima de } j ) - (\text{ número de rankings con } i \text{ por debajo de } j ) \]
 
 Si hay $n$ elementos en total entre los $k$ rankings, entonces $C$ es una matriz antisimétrica de tamaño $n \times n$.\\
 
 Armado con una matriz $C$ de constantes que mide la conformidad, nuestro objetivo es crear un ranking de los $n$ elementos que maximice la conformidad. Para lograr este objetivo, definimos variables de decisión $x_{i,j}$ si el elemento $i$ debería estar por encima del elemento $j$ en el ranking, es decir, 
 
 \[ x_{i,j} = \begin{cases}
 1 \quad si \quad \text{si el elemento } $i$ \text{ debería estar por encima del elemento }  $j$ \text{ en el ranking}\\
 0 \quad \text{en caso contrario}
 \end{cases} \]
 
 Queremos maximizar la conformidad entre entre los rankings de entrada, que en términos de nuestras constantes $c_{i,j}$ y las variables $x_{i,j}$ se convierte en:
 
 \[ \max \sum\limits_{i=1}^{n} \sum\limits_{j=1}^{n} c_{i,j} x_{i,j} \quad \text{con } x_{i,j} \in \{0,1\} \] 
 
 Sin embargo, también necesitamos algunas restricciones que son las siguientes:
 
 \[ x_{i,j} + x_{j,i} = 1 \quad \text{para todas las parejas distintas } (i,j)  \quad \text{Tipo 1 (antisimetría)}\]
 \[x_{i,j} + x_{jk} + x_{ki} \leq 2 \quad \text{para todas las tripletas distintas } (i,j,k)  \quad \text{Tipo 2 (transitividad)}
 \]
 
 La matriz $X$ puede ser representada mediante un grafo de dominancia.\\
 
 En resumen, el problema de optimización lineal entera queda así:
 
 \begin{align*}
 \max \sum\limits_{i=1}^{n} \sum\limits_{i=1}^{n} c_{ij} x_{ij} \\
 x_{ij} + x_{ji} = 1 \quad \forall (i,j) \quad i \neq j \\
 x_{ij} + x_{jk} + x_{ki} \leq 2 \quad \forall (i,j,k) \quad i \neq j \neq k\\
 x_{ij} \in \{0,1\}
 \end{align*}
 
 Este problema tiene $n(n-1)$ variables de decisión, $n(n-1)$ restricciones de Tipo 1 y $n(n-1)(n-2)$ restricciones de Tipo 2. Las restricciones de Tipo 2 tienen un orden de $\mathcal{O}(n^3)$, lo que limita enormemente el tamaño de los rankings que pueden ser resueltos con este método de agregación óptimo. Se puede solventar este problema aplicando técnicas como la relajación de constantes y ramifica y poda.\\
 
 Este problema puede no tener solución única.\\
 
 \subsection{Rating diferencial vs. Agregación de rankings}
 
 El método del rating diferencial consiste en encontrar un reordenamiento de los elementos que aplicados a cada uno de los elementos formando una matriz de que está tan cerca de la llamada ``forma de ladera''\footnote{Traducción de hillside form} como sea posible.\\
 
 Este método puede ser resuelto de forma óptima y eficientemente con las técnicas vistas en esta sección. La forma de resolver el método la llamaremos MVR (Minimum Violation Ranking) que minimiza las violaciones de la ladera.\\
 
 El método encaja perfectamente como problema de programación lineal entera y lineal visto anteriormente. Pondremos atención en la matriz $D$ de diferencias de puntos, donde $d_{ij}$ es el número de puntos ganando el equipo $i$ al equipo perdedor $j$ en sus partidos, $0$ en caso contrario. El truco está en pensar cada fila y columna de $D$ como el ranking del equipo de sus oponentes.\\
 
 Sólo nos queda ver la definición de conformidad para este método:
 
 \begin{defi}
 Sea $C = (c_{ij}) \quad \forall i,j = 1,2,\dots,n$ se puede definir como
 
 \[ c_{ij} = \#\{ k \mid d_{ik} < d_{jk} + \#\{ k \mid d_{ki} > d_{kj} \} \]
 
 donde $\#$ denota el cardinal del conjunto correspondiente.
 \end{defi}
 
 \section{Métodos de comparación}
 
 Hasta ahora, sólo hemos cómo crear nuevos rankings y cómo agregarlos para crear otros nuevos. Ahora nos preguntamos ¿qué método para crear rankings es mejor? O en otra palabras, ¿cómo comparamos estos métodos?\\
 
 Determinar entre dos rankings cuál es mejor es un problema complicado, pero otra cuestión relacionada en más fácil de resolver: cómo de apartados están están dos rankings. Dos medidas que miden esto son la tau de Kendall y la ``footrule'' de Spearman, que veremos más adelante.\\
 
 Mientras que las desviaciones numéricas nos dan una medida para comparar dos rankings, una medida imprecisa también se puede usar a veces. Una medida imprecisa es la representación gráfica, que consiste en unir mediante líneas los nodos de cada uno de los rankings. En caso de tener rankings parciales, podemos añadir nodos ficticios para tener un ranking completo y proceder como hemos visto. Este método también puede ser usado para ratings.
 
 \subsection{Tau de Kendall} 
 
 Kendall originalmente definió su medida para rankings completos, y necesita algunos ajustes para ser aplicada a rankings parciales.
 
 \paragraph{Tau de Kendall para rankings completos}
 
 En 1938 Maurice Kendall desarrolló una medida conocida como la tau de correlación de Kendall para rankings que determina la correlación entre dos rankings completos de igual tamaño. La tau de Kendall nos da el grado en que una un ranking coincide (o no) con otro. Una forma de calcular parte de esta medida es contar el número de intercambios de posición por el algoritmo de la burbuja para permutar un ranking en el otro. Sin embargo, la definición común de tau de Kendall es:
 
 \[ \tau = \dfrac{n_c - n_d}{n(n-1)/2} \]
 
 donde $n_c$ es el número de pares que concuerdan y $n_d$ es el número de pares discordantes. El denominador es el número total de pares de $n$ elementos en los rankings. Para cada par de elementos en el ranking, determinamos si entre dos rankings relativos entre los dos rankings coinciden. Es decir, para el par $(i,j)$ si el equipo $i$ se encuentra por encima (o debajo) del equipo $j$ en ambos rankings, entonces el par concuerda. En otro caso, se dice que es discordante. La representación fraccional de $\tau$ revela su medida de concordancia entre dos rankings.  Claramente, $-1 \leq \tau \leq 1$. Si $\tau = 1$, los dos rankings coinciden plenamente, y si $\tau = -1$, un ranking es el inverso del otro.\\
 
 Esta medida tiene algunas desventajas. Es computacionalmente caro de computar cuando los rankings son grandes. Los rankings tienes que ser completos, que limita la aplicabilidad del método. Debilidad entre errores en la parte inferior de los rankings.
 
 \paragraph{Tau de Kendall para rankings parciales}
 
 La tau de Kendall necesita algunos ajustes para ser aplicada a rankings parciales de tamaño variable. Modificamos la tau de Kendall para rankings completos para cubrir los rankings parciales, incluyendo los rankings parciales de tamaño variable y rankings que contienen empates.
 
 \[ \tau_{\text{parcial}} = \dfrac{n_c - n_d - n_u}{\binom{n}{2} - n_u} \]
 
 donde $n_c, n_d$ designan lo mismo que en la sección anterior, $n$ es el número de elementos únicos en los rankings, y $n_u$ es el número de pares no nombrados en los rankings. Se tiene que 
 
 \[ -\dfrac{\binom{n}{2}}{\binom{n}{2} - n_u} \leq \tau_{\text{parcial}} \leq \dfrac{\binom{n}{2}}{\binom{n}{2} - n_u} \]
 
 Una ventaja de $\tau_{\text{parcial}}$ es que da una mayor penalización a los rankings parciales disjuntos que a los rankings que invierten su orden.